import os
import json
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
from astrbot.api.message_components import Plain
import aiohttp
from bs4 import BeautifulSoup

@register("AstrBot_plugin_0721anime", "mingrixiangnai", "0721åŠ¨æ¼«æœç´¢", "1.0", "https://github.com/mingrixiangnai/0721anime")
class DM0721SearchPlugin(Star):
    def __init__(self, context: Context):
        super().__init__(context)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
            'Referer': 'https://dm0721.icu/'
        }
        self.base_url = 'https://dm0721.icu/p_sousuo.html?wd='

    @filter.command("æŸ¥ç•ª")
    async def search_anime(self, event: AstrMessageEvent):
        '''æŸ¥è¯¢0721åŠ¨æ¼«ä¿¡æ¯\nç”¨æ³•ï¼š/æŸ¥ç•ª åŠ¨æ¼«åç§°'''
        args = event.message_str.split(maxsplit=1)
        if len(args) < 2:
            yield event.plain_result("è¯·è¾“å…¥è¦æŸ¥è¯¢çš„åŠ¨æ¼«åç§°ï¼Œä¾‹å¦‚ï¼š/æŸ¥ç•ª æˆ‘ç‹¬è‡ªå‡çº§")
            return
        
        keyword = args[1]
        try:
            async with aiohttp.ClientSession(headers=self.headers) as session:
                async with session.get(f"{self.base_url}{keyword}") as resp:
                    html = await resp.text()
                    
            soup = BeautifulSoup(html, 'html.parser')
            ul_tag = soup.find('ul', class_='row')
            if not ul_tag:
                yield event.plain_result(f"æœªæ‰¾åˆ°ä¸ã€Œ{keyword}ã€ç›¸å…³çš„åŠ¨æ¼«")
                return
            
            results = []
            for li in ul_tag.find_all('li'):
                anime = {
                    'title': '',
                    'episodes': '',
                    'detail_url': ''
                }
                
                # æå–æ ‡é¢˜å’Œè¯¦æƒ…é“¾æ¥
                name_div = li.find('div', class_='name')
                if name_div:
                    a_tag = name_div.find('a')
                    if a_tag:
                        anime['title'] = a_tag.get('title', '').strip()
                        # å¤„ç†è¯¦æƒ…é“¾æ¥
                        detail_url = a_tag.get('href', '')
                        if detail_url and not detail_url.startswith('http'):
                            detail_url = f"https://dm0721.icu{detail_url}"
                        anime['detail_url'] = detail_url
                    
                    # æå–é›†æ•°
                    p_tag = name_div.find('p')
                    if p_tag:
                        anime['episodes'] = p_tag.get_text(strip=True)
                
                if anime['title']:
                    results.append(anime)

            if not results:
                yield event.plain_result(f"æœªæ‰¾åˆ°ä¸ã€Œ{keyword}ã€ç›¸å…³çš„åŠ¨æ¼«")
                return

            # æ„å»ºåˆå¹¶æ¶ˆæ¯
            msg = [f"ğŸ”æ‰¾åˆ°{len(results)}æ¡ç»“æœï¼š\n"]
            for index, anime in enumerate(results, 1):
                entry = f"{index}.\n   ğŸ“º ã€æ ‡é¢˜ã€‘ï¼š{anime['title']}\n"
                entry += f"   ğŸ¬ ã€é›†æ•°ã€‘ï¼š{anime['episodes']}\n"
                if anime['detail_url']:
                    entry += f"   ğŸ”— ã€è¯¦æƒ…ã€‘ï¼š\n{anime['detail_url']}\n"
                msg.append(entry)
            
            # åˆå¹¶ä¸ºå•æ¡æ¶ˆæ¯å‘é€
            yield event.plain_result("\n".join(msg))

        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {str(e)}", exc_info=True)
            yield event.plain_result("åŠ¨æ¼«æŸ¥è¯¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•")

    async def terminate(self):
        '''æ¸…ç†èµ„æº'''
        pass
